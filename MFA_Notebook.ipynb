{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LGfA1ByTY_rI"
      },
      "outputs": [],
      "source": [
        "#@title Install Whisper and Condacolab\n",
        "!pip install -U openai-whisper\n",
        "!pip install ffmpeg\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(\"All done!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "jpHc_ficaXQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Unzip corpus\n",
        "#@markdown Unzip your dataset for transcription stuff. Make sure it is an archive only containing wavs (15-30 seconds in length recommended).\n",
        "\n",
        "file_location = '/content/drive/MyDrive/wav.zip' #@param {type:\"string\"}\n",
        "\n",
        "!7z x \"$file_location\" -o/content/db\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(\"Wavs extracted in db folder\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "NIJNjFTEav8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Whisper inference\n",
        "#@markdown **Make transcriptions** <br/> Worth noting that your singing database shouldn't have long pauses, *ooh-ing*, lalala-ing, humming etc. in it, otherwise it'll probably break the transcription making (Whisper poorly recognises those).\n",
        "#Implemented from https://github.com/openai/whisper/discussions/1041 by Haru0l\n",
        "\n",
        "import os\n",
        "os.makedirs('/content/txt/', exist_ok=True)\n",
        "!cd /content/db\n",
        "\n",
        "def Transcriber(audiofile):\n",
        "    import whisper\n",
        "    from whisper.tokenizer import get_tokenizer\n",
        "    #encourage model to transcribe words literally\n",
        "    tokenizer = get_tokenizer(multilingual=True)  # use multilingual=True if using multilingual model\n",
        "    number_tokens = [\n",
        "        i\n",
        "        for i in range(tokenizer.eot)\n",
        "        if all(c in \"0123456789\" for c in tokenizer.decode([i]).removeprefix(\" \"))\n",
        "    ]\n",
        "\n",
        "    model = whisper.load_model(\"medium\")\n",
        "    answer = model.transcribe(audiofile, suppress_tokens=[-1] + number_tokens)\n",
        "\n",
        "    print(answer['text'])\n",
        "\n",
        "    output_txt = os.path.join('/content/txt/', os.path.splitext(filename)[0] + '.txt')\n",
        "\n",
        "    with open(output_txt, 'w') as f:\n",
        "      f.write(answer['text'])\n",
        "\n",
        "for filename in os.listdir('/content/db/'):\n",
        "  if filename.endswith('.wav'):\n",
        "    file_path = os.path.join('/content/db/', filename)\n",
        "    Transcriber(file_path)\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(\"Hopefully everything worked and your transcriptions are in the 'txt' folder!\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9lYMRF3qa8Ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (Optional) Zip up text transcriptions `txt` for you to dowload and edit\n",
        "!zip transcriptions.zip /content/txt/*.txt"
      ],
      "metadata": {
        "cellView": "form",
        "id": "X5Aa8T-_eCHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install MFA\n",
        "!conda create -n aligner kaldi pynini\n",
        "!source activate aligner\n",
        "!pip install montreal-forced-aligner\n",
        "!source activate aligner\n",
        "!pip install speechbrain\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(\"All done!\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TTxXkGZBmrs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download the alignment models\n",
        "#@markdown Choose the model for your desired language and scroll down to find the name of the model under \"Installation\"<br>After \"mfa model download acoustic/dictionary\" (e.g.: italian_cv)<br>Acoustic models: https://mfa-models.readthedocs.io/en/latest/acoustic/index.html<br>Dictionaries: https://mfa-models.readthedocs.io/en/latest/dictionary/index.html\n",
        "!mv /content/txt/*.txt /content/db\n",
        "acoustic = 'french_mfa' #@param {type:\"string\"}\n",
        "dictionary = 'french_mfa' #@param {type:\"string\"}\n",
        "\n",
        "# Download Model\n",
        "!source activate aligner\n",
        "!mfa model download acoustic \"$acoustic\"\n",
        "# Download G2P\n",
        "!source activate aligner\n",
        "!mfa model download dictionary \"$dictionary\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "G5dox6_obfEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Make alignments**\n",
        "!source activate aligner\n",
        "!mfa align /content/db \"$acoustic\" \"$dictionary\" /content/alignment --beam 400\n",
        "#mfa align --custom_mapping_path /content/arpa_cleaners.yaml /content/db english_us_arpa english_us_arpa /content/alignment\n",
        "# Thank u HAI-D I'd probably die figuring out myself"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6mU0FwKceLIL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KahazaTester/MFA-Universal-Notebook/blob/whisper-transformers/MFA_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **[Montreal Forced Aligner](https://montreal-forced-aligner.readthedocs.io/)**\n",
        "_Command line utility for forced alignment using Kaldi_\n",
        "\n",
        "\\\n",
        "____\n",
        "\\\n",
        "\n",
        "## _Known issues:_\n",
        "- It really struggles with long silences, long notes and humming.\n",
        "\n",
        "- It's really dependent on Whisper's performance as well, which isn't always perfect: if you want a better base it's highly recommended to edit the transcriptions!\n",
        "\n",
        "- The pretrained dictionaries for MFA are often lackluster and/or inaccurate when transposed to singing, which affects the label quality (I've particularly noticed this with French).\n",
        "\n",
        "- It's possible to supplement the dictionaries with G2P models, but I haven't implemented that.\n",
        "\n",
        "\\\n",
        "____\n"
      ],
      "metadata": {
        "id": "sfxFpUjTLMzO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Huge thanks to PixPrucer and HAI-D for basically making every part of this notebook. I just updated things around basically â›¹"
      ],
      "metadata": {
        "id": "M52QImcigVUk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Upload files**"
      ],
      "metadata": {
        "id": "VdX5jLV9btep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "jpHc_ficaXQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Unzip corpus\n",
        "#@markdown Unzip your dataset for transcription stuff. Make sure it is an archive only containing wavs (15-30 seconds in length recommended).<br>If your samples are long you can use the audio slicer below.\n",
        "\n",
        "file_location = '/content/drive/MyDrive/wav.zip' #@param {type:\"string\"}\n",
        "\n",
        "!7z x \"$file_location\" -o/content/db\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(\"Wavs extracted in db folder\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "NIJNjFTEav8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (Optional) Unzip edited transcriptions\n",
        "#@markdown Unzip your own transcriptions into the `txt` folder so you don't need to use Whisper.\n",
        "\n",
        "file_location = '/content/drive/MyDrive/txt.zip' #@param {type:\"string\"}\n",
        "\n",
        "!7z x \"$file_location\" -o/content/txt\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(\"Transcriptions extracted in txt folder\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "mHmxkQ8qM_5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (Optional) Audio-slicer"
      ],
      "metadata": {
        "id": "w1tCMjzfBLQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Slice it up!\n",
        "!git clone https://github.com/openvpi/audio-slicer\n",
        "!pip install librosa\n",
        "!pip install soundfile\n",
        "!mkdir /content/slicer-temp\n",
        "!mv /content/db/*.wav /content/slicer-temp/\n",
        "import os\n",
        "\n",
        "# Change directory to the audio-slicer folder\n",
        "os.chdir('/content/slicer-temp')\n",
        "\n",
        "# Loop through all files in the folder\n",
        "for filename in os.listdir():\n",
        "    # Check if the file is a .wav file\n",
        "    if filename.endswith('.wav'):\n",
        "        # Execute the command for the current file\n",
        "        !python /content/audio-slicer/slicer2.py /content/slicer-temp/\"$filename\" --out /content/db/\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(\"Your sliced audios should be in the 'db' folder and the old files will be in the 'slicer-temp' folder\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "qr2vsz9KCBe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Whisper inference (Auto-transcriptions)**"
      ],
      "metadata": {
        "id": "gda9JsuGQ0ji"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LGfA1ByTY_rI"
      },
      "outputs": [],
      "source": [
        "#@title Install Whisper\n",
        "!pip install -U openai-whisper\n",
        "!pip install ffmpeg\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(\"All done!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Whisper inference\n",
        "#@markdown **Make transcriptions** <br/> Worth noting that your singing database shouldn't have long pauses, *ooh-ing*, lalala-ing, humming etc. in it, otherwise it'll probably break the transcription making (Whisper poorly recognises those).\n",
        "#Implemented from https://github.com/openai/whisper/discussions/1041 by Haru0l\n",
        "\n",
        "import os\n",
        "os.makedirs('/content/txt/', exist_ok=True)\n",
        "!cd /content/db\n",
        "\n",
        "def Transcriber(audiofile):\n",
        "    import whisper\n",
        "    from whisper.tokenizer import get_tokenizer\n",
        "    #encourage model to transcribe words literally\n",
        "    tokenizer = get_tokenizer(multilingual=True)  # use multilingual=True if using multilingual model\n",
        "    number_tokens = [\n",
        "        i\n",
        "        for i in range(tokenizer.eot)\n",
        "        if all(c in \"0123456789\" for c in tokenizer.decode([i]).removeprefix(\" \"))\n",
        "    ]\n",
        "\n",
        "    model = whisper.load_model(\"medium\")\n",
        "    answer = model.transcribe(audiofile, suppress_tokens=[-1] + number_tokens)\n",
        "\n",
        "    print(answer['text'])\n",
        "\n",
        "    output_txt = os.path.join('/content/txt/', os.path.splitext(filename)[0] + '.txt')\n",
        "\n",
        "    with open(output_txt, 'w') as f:\n",
        "      f.write(answer['text'])\n",
        "\n",
        "for filename in os.listdir('/content/db/'):\n",
        "  if filename.endswith('.wav'):\n",
        "    file_path = os.path.join('/content/db/', filename)\n",
        "    Transcriber(file_path)\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(\"Hopefully everything worked and your transcriptions are in the 'txt' folder!\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9lYMRF3qa8Ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (Optional) Zip up text transcriptions `txt` for you to dowload and edit\n",
        "#@markdown Make sure there's only .txt files in your .zip archive!\n",
        "!zip -r transcriptions.zip /content/txt/*.txt\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(\"Your transcriptions are now in 'transcriptions.zip'\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "X5Aa8T-_eCHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Auto-alignment (MFA)**"
      ],
      "metadata": {
        "id": "crRwh8xgb8tX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Condacolab\n",
        "#@markdown The session will crash and restart, that's normal!\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(\"All done, please wait for the session to restart!\")"
      ],
      "metadata": {
        "id": "TTxXkGZBmrs3",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install MFA\n",
        "!conda install -c conda-forge montreal-forced-aligner spacy sudachipy sudachidict-core\n",
        "!pip install speechbrain\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(\"All done!\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "HY_iUJGBwT3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download the alignment models\n",
        "#@markdown Choose the model for your desired language and scroll down to find the name of the model under \"Installation\"<br>After \"mfa model download acoustic/dictionary\" (e.g.: italian_cv)<br>Acoustic models: https://mfa-models.readthedocs.io/en/latest/acoustic/index.html<br>Dictionaries: https://mfa-models.readthedocs.io/en/latest/dictionary/index.html\n",
        "acoustic = 'japanese_mfa' #@param {type:\"string\"}\n",
        "dictionary = 'japanese_mfa' #@param {type:\"string\"}\n",
        "# Download Model\n",
        "!mfa model download acoustic \"$acoustic\"\n",
        "# Download G2P\n",
        "!mfa model download dictionary \"$dictionary\"\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(\"Alignment models downloaded!\")\n"
      ],
      "metadata": {
        "id": "G5dox6_obfEp",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Start aligning!\n",
        "!mv /content/txt/*.txt /content/db\n",
        "!mfa align /content/db \"$dictionary\" \"$acoustic\" /content/alignment --beam 400\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(\"All done! Check the 'alignment' folder for .TextGrid files\")"
      ],
      "metadata": {
        "id": "6mU0FwKceLIL",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**LAB Converter**"
      ],
      "metadata": {
        "id": "5sC5QWZqcBEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install TextGrid to LAB converter\n",
        "!pip install mytextgrid\n",
        "!git clone https://github.com/gnloop/MFA-Universal-Notebook\n",
        "!mv /content/MFA-Universal-Notebook/text2lab_test.py /content/alignment/\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(\"All done!\")"
      ],
      "metadata": {
        "id": "TTbvrwN6HEsx",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HALT! Before you go happily converting your TextGrid files, if your language is not present in the dropdown list below, you're gonna have to make your own 'custom_converter.txt' in the converters folder!\n",
        "#### Most MFA models use some sort of IPA system which doesn't sit well with DiffSinger. The default converter.txt file is set up for English: it changes every phoneme from uppercase to lowercase and deletes any numbers.\n",
        "#### For further details on what phonemes MFA uses, you should check out the webpage where the MFA models are listed. There's usually a phoneme list there as well."
      ],
      "metadata": {
        "id": "4NPGauk2LiK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Convert TextGrid to LAB\n",
        "converter = 'converter_JP' #@param ['converter_JP', 'converter_EN-ARPA', 'converter_ES', 'converter_IT', 'custom_converter']\n",
        "!python -X utf8 /content/alignment/text2lab_test.py -c /content/MFA-Universal-Notebook/converters/\"$converter\".txt\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(\"Your .lab files should now be under the 'alignment' folder!\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "bi7CR7lNKTfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (ITALIAN ONLY) Gemination fix\n",
        "#@markdown This splits double consonants into 2 separate phonemes to adapt to the current Italian implementation on OpenUTAU<br>(You'll still need to turn 'u' and 'i' into 'w' and 'y' for consonant clusters!)\n",
        "import re\n",
        "import os\n",
        "\n",
        "def divide_double_consonants(lab_file_path):\n",
        "    \"\"\"Divides double consonants in a monophonic HTS .lab file,\n",
        "       excluding 'rr', and adjusts durations.\n",
        "\n",
        "    Args:\n",
        "        lab_file_path: The path to the .lab file.\n",
        "    \"\"\"\n",
        "    with open(lab_file_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    modified_lines = []\n",
        "    for line in lines:\n",
        "        parts = line.strip().split()\n",
        "        if len(parts) == 3:  # Check if it's a valid label line\n",
        "            start_time, end_time, phoneme = parts\n",
        "            # Find double consonants excluding \"rr\"\n",
        "            double_consonants = re.findall(r'(?!rr)([a-z])\\1', phoneme)\n",
        "            if double_consonants:\n",
        "                duration = float(end_time) - float(start_time)\n",
        "                half_duration = duration / 2\n",
        "                # Split the label into two with half durations, using integers for timestamps\n",
        "                modified_lines.append(f\"{int(float(start_time))} {int(float(start_time) + half_duration)} {double_consonants[0]}\\n\")\n",
        "                modified_lines.append(f\"{int(float(start_time) + half_duration)} {int(float(end_time))} {double_consonants[0]}\\n\")\n",
        "            else:\n",
        "                modified_lines.append(line)  # Keep original line if no double consonants\n",
        "        else:\n",
        "            modified_lines.append(line)  # Keep lines that are not labels\n",
        "\n",
        "    with open(lab_file_path, 'w') as f:\n",
        "        f.writelines(modified_lines)\n",
        "\n",
        "# Specify the folder containing your .lab files\n",
        "folder_path = '/content/alignment/'  # Replace with your folder path\n",
        "\n",
        "# Loop through all files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith('.lab'):  # Process only .lab files\n",
        "        lab_file_path = os.path.join(folder_path, filename)\n",
        "        divide_double_consonants(lab_file_path)\n",
        "\n",
        "print(\"Double consonants divided in all .lab files in the folder!\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ij9VwRyCPkll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Zip labels\n",
        "!zip -r /content/labels.zip /content/alignment/*.lab\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(\"You can now download your labels in the labels.zip file!\")"
      ],
      "metadata": {
        "id": "uRn0oWwkM5ny",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Extras**"
      ],
      "metadata": {
        "id": "6n0MUMW6OZkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Whisper (Transformers) inference\n",
        "#@markdown **Make transcriptions** <br/> Only use this if you know what you are doing\n",
        "#Implemented from https://github.com/openai/whisper/discussions/1041 by Haru0l, edited to be compatible with Transformers HuggingFace implementation\n",
        "\n",
        "!pip install --upgrade pip\n",
        "!pip install --upgrade transformers accelerate torchaudio\n",
        "!pip install \"punctuators==0.0.5\"\n",
        "!pip install \"pyannote.audio\"\n",
        "!pip install git+https://github.com/huggingface/diarizers.git\n",
        "\n",
        "from transformers import pipeline\n",
        "import os\n",
        "\n",
        "os.makedirs('/content/txt/', exist_ok=True)\n",
        "\n",
        "#@markdown <b><font size=\"3.5\"> Model name (HuggingFace)\n",
        "model_name = \"openai/whisper-medium\"  #@param {type:\"string\"}\n",
        "#@markdown <b><font size=\"3.5\"> generate_kwarts\n",
        "language = \"Japanese\"  #@param {type:\"string\"}\n",
        "no_repeat_ngram_size = 0  #@param {type:\"integer\"}\n",
        "repetition_penalty = 1.0  #@param {type:\"number\"}\n",
        "\n",
        "generate_kwargs = {\n",
        "    \"language\": language,\n",
        "    \"no_repeat_ngram_size\": no_repeat_ngram_size,\n",
        "    \"repetition_penalty\": repetition_penalty,\n",
        "}\n",
        "\n",
        "def transcriber(audiofile):\n",
        "    transcriber = pipeline(\"automatic-speech-recognition\", model=model_name, generate_kwargs=generate_kwargs)\n",
        "\n",
        "    print(f\"Processing files: {audiofile}\")\n",
        "    result = transcriber(audiofile)\n",
        "\n",
        "    transcription = result['text']\n",
        "    print(transcription)\n",
        "\n",
        "    output_txt = os.path.join('/content/txt/', os.path.splitext(os.path.basename(audiofile))[0] + '.txt')\n",
        "    with open(output_txt, 'w') as f:\n",
        "        f.write(transcription)\n",
        "\n",
        "audio_directory = '/content/db/'\n",
        "for filename in os.listdir(audio_directory):\n",
        "    if filename.endswith('.wav'):\n",
        "        file_path = os.path.join(audio_directory, filename)\n",
        "        transcriber(file_path)\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(\"Hopefully everything worked and your transcriptions are in the 'txt' folder!\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1L-Sx48oOh8Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}